#!/bin/bash
# vextuClone - Termux web cloner
# Descarga todo el contenido de una web (HTML, CSS, JS, JSON, im√°genes)

# Requerimientos: curl, grep, sed
# Librer√≠as internas
LIB_DIR="$HOME/.vextuClone-lib"
mkdir -p "$LIB_DIR"

# Descargar librer√≠as si no existen
[ ! -f "$LIB_DIR/network.sh" ] && \
curl -sL https://raw.githubusercontent.com/WM-HTML/VextuClone/refs/heads/main/network.sh -o "$LIB_DIR/network.sh"

[ ! -f "$LIB_DIR/parser.sh" ] && \
curl -sL https://raw.githubusercontent.com/WM-HTML/VextuClone/refs/heads/main/parser.sh -o "$LIB_DIR/parser.sh"

# Cargar librer√≠as
source "$LIB_DIR/network.sh"
source "$LIB_DIR/parser.sh"

# URL a clonar
URL="$1"
if [ -z "$URL" ]; then
    echo "üåê Uso: vextuClone <URL>"
    exit 1
fi

# Limpiar esquema
HOST=$(echo "$URL" | sed -E 's#https?://##; s#/.*##')
SCHEME=$(echo "$URL" | sed -E 's#(https?)://.*#\1#')
PORT=80
[ "$SCHEME" = "https" ] && PORT=443

# Carpeta de destino
DEST="/sdcard/Download/VextuClone/$(echo $HOST | sed 's#/#_#g')"
mkdir -p "$DEST"

echo "üåê Descargando $URL a $DEST..."

# Descargar HTML principal
curl -sL "$URL" -o "$DEST/index.html"

# Parsear y descargar CSS, JS, JSON e im√°genes
extract_css "$DEST/index.html" "$DEST"
extract_js "$DEST/index.html" "$DEST"
extract_json "$DEST/index.html" "$DEST"
extract_img "$DEST/index.html" "$DEST"

echo "‚úÖ Descarga completada en $DEST"
